---
title: "AoA prediction template"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
options(dplyr.summarise.inform = FALSE)

# load libraries
library(tidyverse)
library(glue)
library(wordbankr)
library(childesr)
library(broom)
library(jglmm)
library(modelr)

# load functions
walk(list.files("scripts", pattern = "*.R$", full.names = TRUE), source)
```

This template provides the structure for how to fit age of acquisition (AoA) prediction models, using data and scripts in this repository.

The general steps are:
- loading the provided CDI data and predictor data
- adding your predictor(s) to the provided predictor data
- using the functions in `scripts/prep_data.R` to prepare the data for modeling
- using the functions in `scripts/fit_models.R` to fit models and extract information from them


# Wordbank data

Loading cached Wordbank data for English:
```{r}
eng_wb_data <- readRDS("data/wordbank/english_(american).rds")
eng_wb_data
```

Loading cached Wordbank data for multiple languages:
```{r}
target_langs <- c("Croatian", "Danish", "English (American)", "Nowegian", "Russian", "Turkish", "French (French)", "Spanish (Mexican)", "Italian", "Swedish",  "English (Australian)", "German", "English (British)")
# "Croatian", "Danish", "English (American)", , "Italian", "Norwegian", "Russian", "Spanish #(Mexican)", "Swedish", "Turkish",  "German","English (Australian)", "English (British)", #"French (French)")
#"Spanish (European)" Portuguese (European) French (Quebecois)

wb_data <- map_df(target_langs, function(lang) {
  message(glue("Loading data for {lang}..."))
  norm_lang <- normalize_language(lang)
  readRDS(glue("data/wordbank/{norm_lang}.rds"))
})
```

Creating saved Wordbank data for English:
```{r, eval=FALSE}
create_wb_data("Portuguese (European)")
```

Creating saved Wordbank data for many languages:
```{r, eval=FALSE}
walk(target_langs, create_wb_data)
```

Creating saved Wordbank data one step at a time (potentially making changes between steps):
```{r, eval=FALSE}
eng_wg <- create_inst_data("English (American)", "WG")
eng_ws <- create_inst_data("English (American)", "WS")
eng_wg_summary <- collapse_inst_data(eng_wg)
eng_ws_summary <- collapse_inst_data(eng_ws)
eng_comb_summary <- combine_form_data(list(eng_wg_summary, eng_ws_summary))
```


# Predictors

Merge in the by-concept predictors (babiness, concreteness, etc) to the unilemmas and the by word predictors (phonemes) to the words/definitions.

```{r}
uni_lemmas <- get_uni_lemmas(wb_data)

babiness_map <- c(word = "word", babiness = "babyAVG")
babiness <- uni_lemmas |> map_predictor("babiness", babiness_map)

valence_map <- c(word = "Word", valence = "V.Mean.Sum", arousal = "A.Mean.Sum")
valence <- uni_lemmas |> map_predictor("valence", valence_map)

concreteness_map <- c(word = "Word", concreteness = "Conc.M")
concreteness <- uni_lemmas |> map_predictor("concreteness", concreteness_map)
```

```{r, eval=FALSE}
# TODO: requires espeak
# http://espeak.sourceforge.net

phonemes <- uni_lemmas |> map_phonemes()
# left_join(phonemes, by = c("language", "uni_lemma")) |>
```

Loading cached CHILDES data for English:
```{r}
eng_childes <- readRDS("data/childes/uni_metrics_english_(american).rds")
eng_childes
```

Loading cached CHILDES data for multiple languages:
```{r}
uni_lemma_map <- build_uni_lemma_map(uni_lemmas)

childes_metrics <- map_df(target_langs, function(lang) {
  message(glue("Loading CHILDES data for {lang}..."))
  norm_lang <- normalize_language(lang)
  readRDS(glue("data/childes/uni_metrics_{norm_lang}.rds"))
})
```

Creating saved CHILDES data for English, potentially changing which metrics are computed and/or arguments that are passed to `childesr`:
```{r, eval=FALSE}
metric_funs <- list(compute_count, compute_mlu, compute_positions,
                    compute_length_char, compute_length_phon)
corpus_args <- list(corpus = NULL, role = NULL, role_exclude = "Target_Child",
                    age = NULL, sex = NULL, part_of_speech = NULL, token = "*")

get_childes_metrics("French (Quebecois)", metric_funs, corpus_args)
get_uni_lemma_metrics("French (Quebecois)", uni_lemma_map)
```

Creating saved CHILDES data for many languages:
```{r, eval=FALSE}
walk(target_langs, get_childes_metrics, metric_funs, corpus_args)
walk(target_langs, get_uni_lemma_metrics, uni_lemma_map)
```

Normalize frequency:
```{r}
#the output has: 
#1. raw counts of uni_lemmas (count, count_first, count_last, count_solo)
#2. sum count of whole CHILDES corpus (sumcount, sumcount_first, sumcount_last, sumcount_solo)
#3. freq_raw is the raw frequency (dividing count / sumcount)
childes_metrics <- normalize_frequency(childes_metrics)  

# residualize frequency out of final and solo frequencies

childes_metrics$final_frequency <- do_residualization(childes_metrics$final_frequency, childes_metrics$frequency)
childes_metrics$solo_frequency  <- do_residualization(childes_metrics$solo_frequency, childes_metrics$frequency)
childes_metrics$first_frequency  <- do_residualization(childes_metrics$first_frequency, childes_metrics$frequency)

```

Combine mapped predictors and CHILDES predictors:
```{r}
uni_joined <- uni_lemmas |>
  left_join(babiness, by = c("language", "uni_lemma")) |>
  left_join(valence, by = c("language", "uni_lemma")) |>
  left_join(concreteness, by = c("language", "uni_lemma")) |>
  left_join(childes_metrics, by = c("language", "uni_lemma"))

#uni_joined <- uni_joined %>% filter(!is.na(frequency))

```

Residualize solo freq and final freq

```{r}


```

```{r impute}
prepped_data <- uni_joined |>
  # select out just the by lexical item data
  unnest(cols = "items") |>
  # select(-c(age, num_true, total, form, item_id)) |>
  distinct() |>
  # pull out categories from classes
  mutate(lexical_category = if_else(str_detect(lexical_class, ","), "other",
                                    lexical_class),
         # collapse v, adj, adv into one category
         lexical_category = lexical_category |> as_factor() |>
           suppressWarnings(
             fct_collapse("predicates" = c("verbs", "adjectives", "adverbs"))
             )) |>
  select(-lexical_class)

pred_sources <- list(
  c("frequency", "mlu", "final_frequency", "first_frequency", "solo_frequency"),
  c("valence", "arousal"),
  c("concreteness", "babiness"),
  c("length_char"),
  c("n_tokens"))


imputed_data <- prepped_data |> do_full_imputation(pred_sources, 20)

```


# Model fitting

aoa lm model:
```{r aoa-lm}



wb_data <- wb_data |>
  mutate(num_false = total - num_true,
         prop = num_true / total) |>
  select(language, measure, uni_lemma, prop, num_true,age, num_false, total, items) %>%
         unique()

aoas <- wb_data |>
  group_by(language, measure) |>
  nest() |>
  mutate(aoa = map(data, get_aoas, max_steps = 400)) |>
  select(-data) |>
  unnest(cols = c(aoa))

word_values <- aoas |>
  left_join(imputed_data |>
              select(-data) |>
              unnest(cols = c(imputed)), 
            by = c("language", "uni_lemma")) 


joined_data <- wb_data |>
  left_join(word_values, by = c("language", "measure", "uni_lemma"))


predictors <- pred_sources |> unlist() 
list1= c("frequency", "mlu","final_frequency","valence", "arousal", "concreteness", 
             "babiness", "first_frequency", "solo_frequency") #, "char_length", "n_tokens"
list2=c("frequency","final_frequency", "first_frequency", "solo_frequency")
list3=c("valence", "arousal", "concreteness", "babiness")
list4= c("frequency", "mlu","final_frequency", "first_frequency", "solo_frequency")
list5= c("frequency", "mlu")
list6= c("frequency", "valence", "arousal", "concreteness", "babiness")
#list7= c("mlu", "valence", "arousal", "concreteness", "babiness")

preds=list(list1,list2, list3, list4, list5, list6, c("frequency"), c("mlu"), c("final_frequency"), c("valence"), c("arousal"), c("concreteness"), c("babiness"), c("first_frequency"), c("solo_frequency"))#c("char_length"), c("n_tokens")


fitted_aoa_models <- map_df(preds, fit_models, joined_data, full = FALSE)
saveRDS(fitted_aoa_models, "data/fitted_aoa_models_whole.rds")


fitted_aoa_models <- fit_models(predictors,joined_data,  full = FALSE)

saveRDS(fitted_aoa_models, "data/fitted_aoa_models.rds")

```

age glmer model:
```{r age-glmer}
## TODO: fix fit_models; currently failing in Julia
#fitted_age_models <- fit_models(joined_data, predictors, full = TRUE)
```

Cross-validation:
```{r}

cv_model <- function(preds, loo_df, lang, meas){
 loo_models <- fit_cv_models(word_values, list(make_effs_formula(preds, FALSE, TRUE)), loo_df)
 loo_preds <- get_cv_preds(loo_models, word_values)
 cv_results <- get_cv_results(loo_preds) 
 cv <-cv_results %>%
 select(mean_abs_dev, ci_mad_min, ci_mad_max) %>% 
 mutate(language=lang, measure=meas, pr=list(preds))
 return(cv)
}


cv_model_lex <- function(preds, loo_df, lang, meas){
 loo_models <- fit_cv_models(word_values, list(make_effs_formula(preds, FALSE, TRUE)), loo_df)
 loo_preds <- get_cv_preds(loo_models, word_values)
 a<- head(arrange(loo_preds, desc(abs_dev)),50) %>% 
  group_by(lexical_category) %>%
  summarise(count=n()) %>%
  mutate(language=lang, measure=meas, pr=list(preds))
 return(a)
}


main_cvpred <- function(lang, meas){
word_v<- word_values %>%  filter(measure ==meas, language==lang)
targetl<- unique(word_v$language) 
cv_df<-function(lang, meas){
 word_values<- word_values %>%  filter(measure ==meas, language==lang)
 loo_df <- crossv_loo(ungroup(word_values))
 m<-map_df(preds, cv_model, loo_df, lang, meas)
 return(m)
} 
if (length(targetl) != 0){
r<- map_df(targetl, cv_df, meas)
return(r)
}
}

cv_across_lang <- map_df(target_langs, main_cvpred, meas="produces") %>%
  rbind(map_df(target_langs, main_cvpred, meas="understands") )

saveRDS(cv_across_lang, "data/cv_across_lang.rds")


main_cvpredlex <- function(lang, meas){
word_v<- word_values %>%  filter(measure ==meas, language==lang)
targetl<- unique(word_v$language) 
cv_df_l<-function(lang, meas){
 word_values<- word_values %>%  filter(measure ==meas, language==lang)
 loo_df <- crossv_loo(ungroup(word_values))
 m<-map_df(preds, cv_model_lex, loo_df, lang, meas)
 return(m)
} 
if (length(targetl) != 0){
r<- map_df(targetl, cv_df_l, meas)
return(r)
}
}

cv_across_lang_lex <- map_df(target_langs, main_cvpredlex, meas="produces") %>%
  rbind(map_df(target_langs, main_cvpredlex, meas="understands") )

saveRDS(cv_across_lang_lex, "data/cv_across_lang_lex.rds")




```

