---
title: "AoA prediction template"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This template provides the structure for how to fit age of acquisition (AoA) prediction models, using data and scripts in this repository.

The general steps are:
- loading the provided CDI data and predictor data
- adding your predictor(s) to the provided predictor data
- using the functions in `scripts/prep_data.R` to prepare the data for modeling
- using the functions in `scripts/fit_models.R` to fit models and extract information from them


# Wordbank data

Example of getting Wordbank data for English:

```{r}
# read in cached data
eng_data <- readRDS("data/wordbank/english_(american).rds")
eng_data
```

```{r}
# use individual functions to read data from db for each form, potentially
# making changes in between steps
source("scripts/wordbank.R")
eng_wg <- create_inst_data("English (American)", "WG")
eng_ws <- create_inst_data("English (American)", "WS")
eng_wg_summary <- collapse_inst_data(eng_wg)
eng_ws_summary <- collapse_inst_data(eng_ws)
eng_summary <- combine_form_data(list(eng_wg_summary, eng_ws_summary))
eng_summary
```

#preprocess and load multiple languages
```{r message=FALSE}

#TODO: French (Quebec) doesn't work?
target_langs <- c("Croatian", "Danish", "English (American)",
  "Italian", "Norwegian", "Russian", "Spanish (Mexican)", "Swedish", "Turkish")

#lapply(target_langs, create_lang_data)

hr_data <- readRDS("data/wordbank/croatian.rds")
da_data <- readRDS("data/wordbank/danish.rds")
eng_data <- readRDS("data/wordbank/english_(american).rds")
it_data <- readRDS("data/wordbank/italian.rds")
no_data <- readRDS("data/wordbank/norwegian.rds")
es_data <- readRDS("data/wordbank/spanish_(mexican).rds")
sv_data <- readRDS("data/wordbank/swedish.rds")
tr_data <- readRDS("data/wordbank/turkish.rds")
ru_data <- readRDS("data/wordbank/russian.rds")
lang_data <- rbind(hr_data, da_data, eng_data, it_data, no_data, es_data, sv_data, tr_data, ru_data)
```

Use `map_predictors.R` to merge in the by-concept predictors (babiness, concreteness, etc) to the unilemmas and the by word predictors (phonemes) to the words/definitions

```{r message=FALSE}
#map in the predictors non-corpus predictors
source("scripts/map_predictors.R")

target_data <- lang_data

babiness_csv <- here("data/predictors/babiness/babiness.csv")
babiness_replace_csv <- here("data/predictors/babiness/babiness_replace.csv")
babiness_map <- c(word = "word", babiness = "babyAVG")

baby_unilemma <- map_predictor(target_data, babiness_csv, babiness_replace_csv, babiness_map)

valence_csv <- here("data/predictors/valence/valence.csv")
valence_replace_csv <- here("data/predictors/valence/valence_replace.csv")
valence_mapping <- c(word = "Word", valence = "V.Mean.Sum", arousal = "A.Mean.Sum")

valence_unilemma <- map_predictor(target_data, valence_csv, valence_replace_csv, valence_mapping)

concreteness_csv <- here("data/predictors/concreteness/concreteness.csv")
concreteness_replace_csv <- here("data/predictors/concreteness/concreteness_replace.csv")
concreteness_map <- c(word = "Word", concreteness = "Conc.M")

conctreteness_unilemma <- map_predictor(target_data, concreteness_csv, 
                                        concreteness_replace_csv, concreteness_map)

#TODO: should this be specified here, or do we assume people will specify it themselves?
lang_code_map <- list(
  "Croatian" = "hr",
  "Danish" = "da",
  "English (American)" = "en-us",
  "French (Quebec)" = "fr",
  "Italian" = "it",
  "Norwegian" = "no",
  "Russian" = "ru",
  "Spanish (Mexican)" = "es",
  "Swedish" = "sv",
  "Turkish" = "tr"
)

phonemes_unilemma <- map_phonemes(target_data, lang_code_map)

uni_joined <- target_data %>% 
  left_join(phonemes_unilemma) %>% 
  left_join(baby_unilemma) %>% 
  left_join(valence_unilemma) %>% 
  left_join(conctreteness_unilemma)
```

Add CHILDES predictors

```{r}
source("scripts/childes.R")
target_langs <- c( "Croatian") #Italian French (French) Russian - !!! stemming from wordbank cyrillic vs stemmer latin

childes_predictors <- lapply(target_langs, get_childes_metrics) %>%
  bind_rows()

clean_childes_predictors <- childes_predictors %>%
  ungroup() %>%
  select(uni_lemma, MLU, frequency, solo_frequency, initial_frequency, final_frequency, nb_realisations_lemma, mean_character_count_lemma, totalcount) %>%
  distinct()

uni_joined_ <- uni_joined %>%
  left_join(clean_childes_predictors)
```


Residualize solo freq and final freq

```{r}


```


```{r impute}
source("scripts/prep_data.R")

prepped_data <- uni_joined %>%
  #select out just the by lexical item data
  unnest(cols = "items") %>%
  select(-c(age, num_true, total, form, item_id)) %>%
  distinct() %>%
  #pull out categories from classes
  mutate(lexical_category = if_else(str_detect(lexical_class, ","), "other", lexical_class),
         # collapse v, adj, adv into one category
         lexical_category = lexical_category %>% as_factor() %>% 
           #TODO: What to do if the languages selected don't have one of these - cant use fct collapse?
           fct_collapse("predicates" = c("verbs", "adjectives", "adverbs"))) %>%
  select(-lexical_class)

pred_sources <- list(
  #c("frequency", "MLU", "final_frequency", "solo_frequency"),
  c("valence", "arousal"), 
  "concreteness", "babiness", "num_phons"
)

imputed_data <- prepped_data %>% do_full_imputation(pred_sources, 20)
```

```{r}
# quick viz of item trajectories
lang_data %>%
  mutate(prop = num_true / total,
         measure = fct_relevel(measure, "understands")) %>%
ggplot(aes(x = age, y = prop)) +
  facet_grid(cols = vars(measure), scales = "free_x", space = "free_x",
             labeller = as_labeller(str_to_sentence)) +
  geom_smooth(aes(colour = uni_lemma, weight = total), alpha = 0.1, size = 0.1,
              se = FALSE, method = "glm", method.args = list(family = "binomial")) +
  scale_colour_discrete(guide = FALSE) +
  scale_x_continuous(breaks = seq(8, 30, 4)) +
  labs(x = "Age (months)", y = "Proportion of children")
```
